{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def load_documents_from_directory(directory_path):\n",
    "    documents = {}\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.txt'):\n",
    "            with open(os.path.join(directory_path, filename), 'r', encoding='utf-8') as file:\n",
    "                documents[filename] = file.read()\n",
    "    return documents\n",
    "\n",
    "# Example usage\n",
    "directory_path = 'path_to_your_text_files_directory'\n",
    "documents = load_documents_from_directory(directory_path)\n",
    "print(f\"Loaded {len(documents)} documents.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# Function to create embeddings\n",
    "def create_embeddings(documents, model_name='sentence-transformers/all-MiniLM-L6-v2', embedding_type='sentence'):\n",
    "    model = SentenceTransformer(model_name)\n",
    "    embeddings = {}\n",
    "    \n",
    "    for doc_name, doc_content in documents.items():\n",
    "        if embedding_type == 'character':\n",
    "            embeddings[doc_name] = model.encode([c for c in doc_content])\n",
    "        elif embedding_type == 'word':\n",
    "            embeddings[doc_name] = model.encode(doc_content.split())\n",
    "        elif embedding_type == 'sentence':\n",
    "            embeddings[doc_name] = model.encode(doc_content.split('.'))\n",
    "        elif embedding_type == 'document':\n",
    "            embeddings[doc_name] = model.encode([doc_content])\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown embedding type: {embedding_type}\")\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "# Example usage\n",
    "embeddings = create_embeddings(documents, embedding_type='document')\n",
    "print(f\"Created embeddings for {len(embeddings)} documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "\n",
    "# Initialize Pinecone\n",
    "pinecone.init(api_key='your_pinecone_api_key', environment='your_pinecone_environment')\n",
    "\n",
    "# Create Pinecone index\n",
    "index_name = 'rag-workshop'\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    pinecone.create_index(index_name, dimension=384)  # Adjust dimension according to your model\n",
    "index = pinecone.Index(index_name)\n",
    "\n",
    "# Function to add embeddings to Pinecone\n",
    "def add_embeddings_to_pinecone(embeddings):\n",
    "    for doc_name, embedding in embeddings.items():\n",
    "        index.upsert([(doc_name, embedding.tolist())])\n",
    "    \n",
    "# Example usage\n",
    "add_embeddings_to_pinecone(embeddings)\n",
    "print(\"Embeddings added to Pinecone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize a language model pipeline\n",
    "llm_pipeline = pipeline('text-generation', model='gpt-3.5-turbo')  # Replace with appropriate model\n",
    "\n",
    "# Function to query the vector database and generate a response\n",
    "def query_rag_system(query, top_k=5):\n",
    "    query_embedding = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2').encode([query])\n",
    "    search_results = index.query(query_embedding.tolist(), top_k=top_k)\n",
    "    \n",
    "    # Retrieve documents\n",
    "    retrieved_docs = [result['id'] for result in search_results['matches']]\n",
    "    \n",
    "    # Generate response using LLM\n",
    "    context = \" \".join([documents[doc_id] for doc_id in retrieved_docs])\n",
    "    response = llm_pipeline(f\"Context: {context}\\nQuestion: {query}\\nAnswer: \")\n",
    "    \n",
    "    return response[0]['generated_text']\n",
    "\n",
    "# Example usage\n",
    "query = \"What is the content of document X?\"\n",
    "response = query_rag_system(query)\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
